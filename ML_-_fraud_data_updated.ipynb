{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c012b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv(r\"C:\\Users\\shras\\Downloads\\fraud_oracle.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0757980",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "222b62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Records: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate records\n",
    "num_duplicates = df1.duplicated().sum()\n",
    "\n",
    "# Printing the number of duplicate records\n",
    "print(\"Number of Duplicate Records:\", num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de2b5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing records where the 'Age' column is 0\n",
    "df_filtered = df1[df1['Age'] != 0]\n",
    "\n",
    "# Saving the filtered DataFrame to a new CSV file for further analysis\n",
    "df_filtered.to_csv('C:/Users/shras/Downloads/filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0ddf485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Make</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>AgeOfVehicle</th>\n",
       "      <th>AgeOfPolicyHolder</th>\n",
       "      <th>PoliceReportFiled</th>\n",
       "      <th>WitnessPresent</th>\n",
       "      <th>AgentType</th>\n",
       "      <th>NumberOfSuppliments</th>\n",
       "      <th>AddressChange_Claim</th>\n",
       "      <th>NumberOfCars</th>\n",
       "      <th>Year</th>\n",
       "      <th>BasePolicy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>3 years</td>\n",
       "      <td>26 to 30</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>6 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>7 years</td>\n",
       "      <td>41 to 50</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun</td>\n",
       "      <td>2</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Jul</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>more than 7</td>\n",
       "      <td>51 to 65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan</td>\n",
       "      <td>5</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>5 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15415</th>\n",
       "      <td>Nov</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Nov</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>6 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1996</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15416</th>\n",
       "      <td>Nov</td>\n",
       "      <td>5</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Pontiac</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Dec</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>6 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1996</td>\n",
       "      <td>Liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15417</th>\n",
       "      <td>Nov</td>\n",
       "      <td>5</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Dec</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>5 years</td>\n",
       "      <td>26 to 30</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1996</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15418</th>\n",
       "      <td>Dec</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Dec</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>2 years</td>\n",
       "      <td>31 to 35</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1996</td>\n",
       "      <td>All Perils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15419</th>\n",
       "      <td>Dec</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Dec</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>5 years</td>\n",
       "      <td>26 to 30</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1996</td>\n",
       "      <td>Collision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15100 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month  WeekOfMonth  DayOfWeek     Make AccidentArea DayOfWeekClaimed  \\\n",
       "0       Dec            5  Wednesday    Honda        Urban          Tuesday   \n",
       "1       Jan            3  Wednesday    Honda        Urban           Monday   \n",
       "2       Oct            5     Friday    Honda        Urban         Thursday   \n",
       "3       Jun            2   Saturday   Toyota        Rural           Friday   \n",
       "4       Jan            5     Monday    Honda        Urban          Tuesday   \n",
       "...     ...          ...        ...      ...          ...              ...   \n",
       "15415   Nov            4     Friday   Toyota        Urban          Tuesday   \n",
       "15416   Nov            5   Thursday  Pontiac        Urban           Friday   \n",
       "15417   Nov            5   Thursday   Toyota        Rural           Friday   \n",
       "15418   Dec            1     Monday   Toyota        Urban         Thursday   \n",
       "15419   Dec            2  Wednesday   Toyota        Urban         Thursday   \n",
       "\n",
       "      MonthClaimed  WeekOfMonthClaimed     Sex MaritalStatus  ...  \\\n",
       "0              Jan                   1  Female        Single  ...   \n",
       "1              Jan                   4    Male        Single  ...   \n",
       "2              Nov                   2    Male       Married  ...   \n",
       "3              Jul                   1    Male       Married  ...   \n",
       "4              Feb                   2  Female        Single  ...   \n",
       "...            ...                 ...     ...           ...  ...   \n",
       "15415          Nov                   5    Male       Married  ...   \n",
       "15416          Dec                   1    Male       Married  ...   \n",
       "15417          Dec                   1    Male        Single  ...   \n",
       "15418          Dec                   2  Female       Married  ...   \n",
       "15419          Dec                   3    Male        Single  ...   \n",
       "\n",
       "       AgeOfVehicle AgeOfPolicyHolder PoliceReportFiled WitnessPresent  \\\n",
       "0           3 years          26 to 30                No             No   \n",
       "1           6 years          31 to 35               Yes             No   \n",
       "2           7 years          41 to 50                No             No   \n",
       "3       more than 7          51 to 65               Yes             No   \n",
       "4           5 years          31 to 35                No             No   \n",
       "...             ...               ...               ...            ...   \n",
       "15415       6 years          31 to 35                No             No   \n",
       "15416       6 years          31 to 35                No             No   \n",
       "15417       5 years          26 to 30                No             No   \n",
       "15418       2 years          31 to 35                No             No   \n",
       "15419       5 years          26 to 30                No             No   \n",
       "\n",
       "      AgentType  NumberOfSuppliments  AddressChange_Claim  NumberOfCars  Year  \\\n",
       "0      External                 none               1 year        3 to 4  1994   \n",
       "1      External                 none            no change     1 vehicle  1994   \n",
       "2      External                 none            no change     1 vehicle  1994   \n",
       "3      External          more than 5            no change     1 vehicle  1994   \n",
       "4      External                 none            no change     1 vehicle  1994   \n",
       "...         ...                  ...                  ...           ...   ...   \n",
       "15415  External                 none            no change     1 vehicle  1996   \n",
       "15416  External          more than 5            no change        3 to 4  1996   \n",
       "15417  External               1 to 2            no change     1 vehicle  1996   \n",
       "15418  External          more than 5            no change     1 vehicle  1996   \n",
       "15419  External               1 to 2            no change     1 vehicle  1996   \n",
       "\n",
       "       BasePolicy  \n",
       "0       Liability  \n",
       "1       Collision  \n",
       "2       Collision  \n",
       "3       Liability  \n",
       "4       Collision  \n",
       "...           ...  \n",
       "15415   Collision  \n",
       "15416   Liability  \n",
       "15417   Collision  \n",
       "15418  All Perils  \n",
       "15419   Collision  \n",
       "\n",
       "[15100 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34fe9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0: 14208\n",
      "Count of 1: 892\n"
     ]
    }
   ],
   "source": [
    "# Counting the occurrences of fraud and non fraud cases from the 'FraudFound_P' column\n",
    "count_of_zero = df_filtered['FraudFound_P'].value_counts().get(0, 0)\n",
    "count_of_one = df_filtered['FraudFound_P'].value_counts().get(1, 0)\n",
    "\n",
    "print(\"Count of 0:\", count_of_zero)\n",
    "print(\"Count of 1:\", count_of_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51797c7d",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8f41e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9397350993377483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2839\n",
      "           1       0.40      0.01      0.02       181\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.67      0.50      0.50      3020\n",
      "weighted avg       0.91      0.94      0.91      3020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Reading the CSV file\n",
    "df = pd.read_csv(\"C:/Users/shras/Downloads/filtered.csv\")\n",
    "\n",
    "# Preprocessing the data\n",
    "X = df.drop(columns=['FraudFound_P'])  # Features\n",
    "y = df['FraudFound_P']  # Target variable\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining which columns should be encoded vs scaled\n",
    "categorical_columns = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "numerical_columns = [col for col in X_train.columns if col not in categorical_columns]\n",
    "\n",
    "# Preprocessing the numerical features\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing the categorical features\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combining preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Applying preprocessing\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Building and training the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Calculating the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21cce7f",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf51530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9400662251655629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2839\n",
      "           1       0.00      0.00      0.00       181\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.47      0.50      0.48      3020\n",
      "weighted avg       0.88      0.94      0.91      3020\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shras\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shras\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shras\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Reading the CSV file\n",
    "df = pd.read_csv(\"C:/Users/shras/Downloads/filtered.csv\")\n",
    "\n",
    "# Preprocessing the data\n",
    "X = df.drop(columns=['FraudFound_P'])  # Features\n",
    "y = df['FraudFound_P']  # Target variable\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identifying categorical columns\n",
    "categorical_columns = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# One-hot encoding categorical variables\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_columns])\n",
    "X_test_encoded = encoder.transform(X_test[categorical_columns])\n",
    "\n",
    "# Standardizing  numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(columns=categorical_columns))\n",
    "X_test_scaled = scaler.transform(X_test.drop(columns=categorical_columns))\n",
    "\n",
    "# Combining encoded categorical features with scaled numerical features\n",
    "import scipy.sparse\n",
    "X_train_final = scipy.sparse.hstack((X_train_scaled, X_train_encoded))\n",
    "X_test_final = scipy.sparse.hstack((X_test_scaled, X_test_encoded))\n",
    "\n",
    "# Building and train the SVM model\n",
    "model = SVC()\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred = model.predict(X_test_final)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Calculating the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a692fe",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbc4ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shras\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9403973509933775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2839\n",
      "           1       1.00      0.01      0.01       181\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.97      0.50      0.49      3020\n",
      "weighted avg       0.94      0.94      0.91      3020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/shras/Downloads/filtered.csv\")\n",
    "\n",
    "# Preprocessing the data\n",
    "X = df.drop(columns=['FraudFound_P'])  # Features\n",
    "y = df['FraudFound_P']  # Target variable\n",
    "\n",
    "# One-hot encoding categorical variables\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "if categorical_cols:\n",
    "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]), index=X.index)\n",
    "    # Getting new column names\n",
    "    encoded_columns = encoder.get_feature_names_out(categorical_cols)\n",
    "    # Updating the names in the DataFrame to be strings\n",
    "    X_encoded.columns = encoded_columns\n",
    "    # Concatenating the original data frame with the new one-hot encoded columns\n",
    "    X = pd.concat([X.drop(columns=categorical_cols), X_encoded], axis=1)\n",
    "\n",
    "# Ensuring all feature names are strings\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building and training the Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Calculating the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6060b73",
   "metadata": {},
   "source": [
    "# SMOTE technique applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f53bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df2 = pd.read_csv(\"C:/Users/shras/Downloads/filtered.csv\")\n",
    "\n",
    "# Encoding categorical variables \n",
    "label_encoders = {}\n",
    "for column in df2.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df2[column] = le.fit_transform(df2[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Separating features and target variable\n",
    "X = df2.drop('FraudFound_P', axis=1)  # Features\n",
    "y = df2['FraudFound_P']  # Target variable\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Applying SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "balanced_df = pd.concat([X_res, y_res], axis=1)\n",
    "\n",
    "# Saving the updated datset to CSV\n",
    "balanced_df.to_csv('C:/Users/shras/Downloads/balanced_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef22b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0: 11369\n",
      "Count of 1: 11369\n"
     ]
    }
   ],
   "source": [
    "# Counting the occurrences of fraud and non fraud cases from the 'FraudFound_P' column\n",
    "\n",
    "df3 = pd.read_csv(\"C:/Users/shras/Downloads/balanced_dataset.csv\")\n",
    "\n",
    "count_of_zero = df3['FraudFound_P'].value_counts().get(0, 0)\n",
    "count_of_one = df3['FraudFound_P'].value_counts().get(1, 0)\n",
    "\n",
    "print(\"Count of 0:\", count_of_zero)\n",
    "print(\"Count of 1:\", count_of_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb2b64",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51b2169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872471416007036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      2282\n",
      "           1       0.85      0.90      0.88      2266\n",
      "\n",
      "    accuracy                           0.87      4548\n",
      "   macro avg       0.87      0.87      0.87      4548\n",
      "weighted avg       0.87      0.87      0.87      4548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df3 = pd.read_csv(\"C:/Users/shras/Downloads/balanced_dataset.csv\")\n",
    "\n",
    "# Defining features and target variable\n",
    "X = df3.drop(columns=['FraudFound_P'])\n",
    "y = df3['FraudFound_P']\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and train logistic regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda7e98",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04d70bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872471416007036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      2282\n",
      "           1       0.85      0.90      0.88      2266\n",
      "\n",
      "    accuracy                           0.87      4548\n",
      "   macro avg       0.87      0.87      0.87      4548\n",
      "weighted avg       0.87      0.87      0.87      4548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initializing and train SVM model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculating classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012dec73",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3451ef62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9610817941952506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      2282\n",
      "           1       0.96      0.96      0.96      2266\n",
      "\n",
      "    accuracy                           0.96      4548\n",
      "   macro avg       0.96      0.96      0.96      4548\n",
      "weighted avg       0.96      0.96      0.96      4548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Initializing and train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculating the evaluation metrics\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "\n",
    "# Calculating the classification report\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(report_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6b892",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9824861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.911169744942832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      2282\n",
      "           1       0.89      0.94      0.91      2266\n",
      "\n",
      "    accuracy                           0.91      4548\n",
      "   macro avg       0.91      0.91      0.91      4548\n",
      "weighted avg       0.91      0.91      0.91      4548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Defining features and target variable\n",
    "X = df3.drop(columns=['FraudFound_P'])\n",
    "y = df3['FraudFound_P']\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and train Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# Calculating the classification report\n",
    "report_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(report_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72c696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
